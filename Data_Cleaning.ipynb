{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Clean investing.com data\n",
    "# https://ca.investing.com/indices/us-spx-500-historical-data \n",
    "\n",
    "def clean_investingcom_df(df, name, country_code):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['day'] = df['Date'].dt.day\n",
    "    df = df.reset_index(drop=True).iloc[::-1]\n",
    "\n",
    "    df['Change %'] = df['Change %'].str.replace('%', '').astype(float)\n",
    "    volatility = df.groupby(by='year')['Change %'].std() * (df.groupby(by='year').size())**0.5\n",
    "\n",
    "    df = df.groupby(by='year').first().reset_index()\n",
    "\n",
    "    df['volatility'] = volatility.values\n",
    "    df['YoY Change'] = df['Price'].pct_change()*100\n",
    "    df['YoY Change'] = df['YoY Change'].shift(-1)\n",
    "\n",
    "    df['code'] = country_code\n",
    "    df['year'] = pd.to_datetime(df['Date']).dt.year\n",
    "    df = df[['year', 'YoY Change', 'volatility', 'code']]\n",
    "    df.dropna(inplace=True)\n",
    "    df.to_csv(f'./Datasets/{name}-Clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = ['S&P500-USA', 'Shanghai-CHN', 'FTSE_JSE-ZAF', 'MASI-MAR', 'NASI-KEN']\n",
    "for dataset in dataset_list:\n",
    "    df = pd.read_csv(f'./Datasets/{dataset}.csv', thousands=',')\n",
    "    clean_investingcom_df(df, dataset, dataset.split('-')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Macrotrends Datasets\n",
    "# These datasets provide us the value of the index on each business day between certain dates\n",
    "# We need to find the values on the first business day of each year, so we can calculate YoY change.\n",
    "\n",
    "def clean_macrotrend_df(df, name, country_code):\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "\n",
    "    df['Day_Change'] = df['value'].pct_change()*100\n",
    "    volatility = df.groupby(by='year')['Day_Change'].std() * (df.groupby(by='year').size())**0.5\n",
    "\n",
    "    # Get the first row representing the first business day of each year\n",
    "    # Code From: https://stackoverflow.com/questions/71002941/get-the-first-row-of-each-group-of-unique-values-in-another-column \n",
    "    df = df.groupby('year', as_index=False).first()\n",
    "    df['volatility'] = volatility.values\n",
    "\n",
    "    df['YoY Change'] = df['value'].pct_change()*100\n",
    "    # Shift YoY Change figures up by 1 row so that YoY Change over 1 year matches with that year for plotting later.\n",
    "    df['YoY Change'] = df['YoY Change'].shift(-1)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop(columns=['month', 'day', 'date', 'value', 'Day_Change'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['code'] = country_code\n",
    "    # Remove first row since it might not be a full year depending on dataset\n",
    "    df = df.iloc[1:]\n",
    "    df = df[['year', 'YoY Change', 'volatility', 'code']]\n",
    "\n",
    "    df.to_csv(f'./Datasets/{name}-Clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.837159716646337\n",
      "1.3604038469467685\n",
      "1.3887348467970342\n",
      "1.6169986807891346\n",
      "1.2302446584311397\n"
     ]
    }
   ],
   "source": [
    "# Clean Macrotrends Datasets\n",
    "# Run function on all of our current MacroTrends Datasets\n",
    "# https://www.macrotrends.net/charts/stock-indexes\n",
    "dataset_list = ['BOVESPA-BRA', 'CAC40-FRA', 'DAX30-DEU', 'HangSeng-HKG', 'Nikkei225-JPN']\n",
    "for dataset in dataset_list:\n",
    "    df = pd.read_csv(f'./Datasets/{dataset}.csv')\n",
    "    clean_macrotrend_df(df, dataset, dataset.split('-')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifty = pd.read_csv('./Datasets/Nifty50-IND.csv')\n",
    "nifty = nifty[['Date', 'Close']]\n",
    "nifty['date'] = pd.to_datetime(nifty['Date'])\n",
    "nifty['year'] = nifty['date'].dt.year\n",
    "nifty['month'] = nifty['date'].dt.month\n",
    "nifty['day'] = nifty['date'].dt.day\n",
    "\n",
    "nifty['Day_Change'] = nifty['Close'].pct_change()*100\n",
    "volatility = nifty.groupby(by='year')['Day_Change'].std() * (nifty.groupby(by='year').size())**0.5\n",
    "\n",
    "# Get the first row representing the first business day of each year\n",
    "nifty = nifty.groupby('year', as_index=False).first()\n",
    "\n",
    "nifty['volatility'] = volatility.values\n",
    "\n",
    "nifty = nifty.iloc[1:]\n",
    "\n",
    "\n",
    "nifty['YoY Change'] = nifty['Close'].pct_change()*100\n",
    "nifty['YoY Change'] = nifty['YoY Change'].shift(-1)\n",
    "nifty['code'] = 'IND'\n",
    "nifty.dropna(inplace=True)\n",
    "nifty.drop(columns=['month', 'day', 'date', 'Date', 'Close', 'Day_Change'], inplace=True)\n",
    "nifty.to_csv('./Datasets/Nifty50-IND-Clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>KOFGI</th>\n",
       "      <th>KOFGIdf</th>\n",
       "      <th>KOFGIdj</th>\n",
       "      <th>KOFEcGI</th>\n",
       "      <th>KOFEcGIdf</th>\n",
       "      <th>KOFEcGIdj</th>\n",
       "      <th>KOFTrGI</th>\n",
       "      <th>...</th>\n",
       "      <th>KOFIpGIdj</th>\n",
       "      <th>KOFInGI</th>\n",
       "      <th>KOFInGIdf</th>\n",
       "      <th>KOFInGIdj</th>\n",
       "      <th>KOFCuGI</th>\n",
       "      <th>KOFCuGIdf</th>\n",
       "      <th>KOFCuGIdj</th>\n",
       "      <th>KOFPoGI</th>\n",
       "      <th>KOFPoGIdf</th>\n",
       "      <th>KOFPoGIdj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1975</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1976</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1977</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1978</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1979</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1980</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1981</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1982</td>\n",
       "      <td>29.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1983</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Angola</td>\n",
       "      <td>1984</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    code country  year  KOFGI  KOFGIdf  KOFGIdj  KOFEcGI  KOFEcGIdf  \\\n",
       "158  AGO  Angola  1975   27.0     33.0     21.0     33.0       38.0   \n",
       "159  AGO  Angola  1976   30.0     33.0     26.0     33.0       38.0   \n",
       "160  AGO  Angola  1977   30.0     33.0     27.0     33.0       38.0   \n",
       "161  AGO  Angola  1978   30.0     33.0     28.0     33.0       38.0   \n",
       "162  AGO  Angola  1979   28.0     33.0     22.0     33.0       37.0   \n",
       "163  AGO  Angola  1980   30.0     33.0     27.0     33.0       37.0   \n",
       "164  AGO  Angola  1981   28.0     34.0     22.0     34.0       39.0   \n",
       "165  AGO  Angola  1982   29.0     32.0     27.0     32.0       36.0   \n",
       "166  AGO  Angola  1983   30.0     32.0     28.0     32.0       36.0   \n",
       "167  AGO  Angola  1984   31.0     32.0     30.0     34.0       37.0   \n",
       "\n",
       "     KOFEcGIdj  KOFTrGI  ...  KOFIpGIdj  KOFInGI  KOFInGIdf  KOFInGIdj  \\\n",
       "158       28.0     40.0  ...       11.0     25.0       39.0       11.0   \n",
       "159       28.0     40.0  ...       14.0     25.0       39.0       11.0   \n",
       "160       28.0     40.0  ...       11.0     25.0       39.0       11.0   \n",
       "161       28.0     40.0  ...       12.0     25.0       39.0       11.0   \n",
       "162       28.0     40.0  ...       12.0     25.0       39.0       11.0   \n",
       "163       28.0     39.0  ...       12.0     25.0       40.0       11.0   \n",
       "164       28.0     41.0  ...       12.0     25.0       38.0       11.0   \n",
       "165       28.0     38.0  ...       13.0     24.0       37.0       11.0   \n",
       "166       28.0     39.0  ...       13.0     23.0       36.0       11.0   \n",
       "167       31.0     40.0  ...       13.0     23.0       34.0       11.0   \n",
       "\n",
       "     KOFCuGI  KOFCuGIdf  KOFCuGIdj  KOFPoGI  KOFPoGIdf  KOFPoGIdj  \n",
       "158     19.0       29.0       10.0     29.0       35.0       23.0  \n",
       "159     20.0       29.0       10.0     37.0       35.0       38.0  \n",
       "160     20.0       29.0       11.0     39.0       35.0       42.0  \n",
       "161     18.0       29.0        8.0     40.0       35.0       45.0  \n",
       "162     18.0       29.0        8.0     32.0       35.0       29.0  \n",
       "163     18.0       28.0        8.0     39.0       35.0       44.0  \n",
       "164     18.0       27.0        9.0     31.0       35.0       26.0  \n",
       "165     18.0       26.0       10.0     37.0       35.0       40.0  \n",
       "166     17.0       26.0        8.0     40.0       35.0       45.0  \n",
       "167     17.0       25.0        9.0     42.0       35.0       49.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "KOF=pd.read_csv('Datasets/KOFGI_2022_public_original.csv')\n",
    "\n",
    "KOF=KOF.dropna() # droping missing value \n",
    "KOF_df=pd.DataFrame(KOF)\n",
    "KOF_df.head(10) # Overview of the  KOF data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only work with the following countries for the period from 1990 until 2020:\n",
    "United States of America (USA), Japan (JPN), France (FRA), Germany (DEU), Brasil (BRA), China (CHN), India (IND), Hong Kong (HKG), South Africa (ZAF), Marocco (MAR) and Kenya (KEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's select the countries that interest us\n",
    "KOF_df = KOF_df[(KOF_df['code'] == 'USA') | (KOF_df['code'] == 'JPN') | (KOF_df['code'] == 'FRA') | \n",
    "    (KOF_df['code'] == 'DEU') | (KOF_df['code'] == 'BRA') | (KOF_df['code'] == 'CHN') | \n",
    "    (KOF_df['code'] == 'IND') | (KOF_df['code'] == 'HKG') | (KOF_df['code'] == 'KEN') |\n",
    "    (KOF_df['code'] == 'MAR') | (KOF_df['code'] == 'ZAF')]\n",
    "\n",
    "# Removed South africa because of missing dataset\n",
    "# | (KOF_df['code'] == 'ZAF')\n",
    "#  Now let's select years between 1990 and 2020\n",
    "KOF_df=KOF_df[(KOF_df['year'] >= 1990) & (KOF_df['year'] <= 2020)]\n",
    "\n",
    "# Here is a overview of our new data frame\n",
    "KOF_df.head(10)\n",
    "KOF_df.to_csv('Datasets/KOF_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script that cleans the world bank index data: https://data.worldbank.org/indicator/CM.MKT.INDX.ZG?view=map\n",
    "# and merges it with the KOF data\n",
    "\n",
    "wb_df = pd.read_csv('./Datasets/World_Bank_Indices.csv')\n",
    "wb_df = wb_df.drop(['Indicator Name', 'Indicator Code', 'Unnamed: 67'], axis=1)\n",
    "\n",
    "excluded_years = [str(i) for i in range(1960, 1995)]\n",
    "active_years = [str(i) for i in range(1995, 2022)]\n",
    "\n",
    "# Drop years that are not in our active time period\n",
    "wb_df = wb_df.drop(excluded_years, axis=1)\n",
    "\n",
    "# Keep only countries with data for at least one year in our active time period\n",
    "wb_df = wb_df.iloc[wb_df[active_years].dropna(axis=0, how='all').index]\n",
    "\n",
    "# Transform into long format, with a row for each year\n",
    "wb_df = pd.melt(wb_df, id_vars=['Country Name', 'Country Code'], value_vars=active_years, var_name='Year', value_name='Pct Change').dropna()\n",
    "\n",
    "#Prep for merge with kof df by making column names match\n",
    "wb_df['year'] = wb_df['Year'].astype(int)\n",
    "wb_df['code'] = wb_df['Country Code']\n",
    "wb_df['country'] = wb_df['Country Name']\n",
    "wb_df = wb_df.drop(['Country Code', 'Year', 'Country Name'], axis=1)\n",
    "\n",
    "kof_df = pd.read_csv('./Datasets/KOFGI_2022_public_original.csv')\n",
    "# Merge dataframes and drop the extra country name column\n",
    "merged_df = pd.merge(wb_df, kof_df, how='inner', left_on=['code', 'year'], right_on=['code', 'year'], suffixes=('', '_duplicated'))\n",
    "\n",
    "merged_df.to_csv('./Datasets/KOF_World_Bank_merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
